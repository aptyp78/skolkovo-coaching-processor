#!/usr/bin/env python3
"""
SKOLKOVO Materials Processor - GUI
===================================
–ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º—ã Executive Coaching.

–ó–∞–ø—É—Å–∫:
    python gui.py

–û—Ç–∫—Ä–æ–µ—Ç—Å—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ –∞–¥—Ä–µ—Å—É http://localhost:7860
"""

import os
import sys
import json
import subprocess
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Tuple, Optional
import tempfile

import gradio as gr

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—â–∏–µ —É—Ç–∏–ª–∏—Ç—ã
sys.path.insert(0, str(Path(__file__).parent))
from utils import (
    load_env_file, mask_api_key, check_api_keys as utils_check_api_keys,
    validate_page_range, get_logger, ensure_directories,
    OUTPUT_DIR, TRANSCRIPTS_DIR, KNOWLEDGE_DIR, BASE_DIR
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –∑–∞–≥—Ä—É–∂–∞–µ–º .env –∏ —Å–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
load_env_file()
ensure_directories()

# –õ–æ–≥–≥–µ—Ä
logger = get_logger(__name__)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –º–æ–¥—É–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
from pdf_vision_processor import PDFVisionProcessor
from audio_transcriber import AudioTranscriber, SeminarProcessor, process_audio_file

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã
try:
    from local_processor import (
        LocalPDFProcessor, LocalVisionProcessor, LocalWhisperTranscriber,
        check_local_requirements, OllamaClient
    )
    LOCAL_AVAILABLE = True
except ImportError:
    LOCAL_AVAILABLE = False
    logger.warning("–õ–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
_current_conversion_process = None


def get_system_memory_gb() -> int:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—ä—ë–º RAM —Å–∏—Å—Ç–µ–º—ã –≤ GB."""
    try:
        import subprocess
        result = subprocess.run(
            ['sysctl', '-n', 'hw.memsize'],
            capture_output=True, text=True, timeout=5
        )
        bytes_ram = int(result.stdout.strip())
        return bytes_ram // (1024 ** 3)
    except Exception:
        return 32  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é


def estimate_model_size(model_name: str) -> tuple:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Ä–∞–∑–º–µ—Ä_–≤_GB, –º–æ–∂–Ω–æ_–∑–∞–ø—É—Å—Ç–∏—Ç—å, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è).
    """
    name_lower = model_name.lower()

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è (7b, 13b, 34b, 70b, 235b, 671b)
    import re
    size_match = re.search(r'(\d+)b', name_lower)

    if size_match:
        params_b = int(size_match.group(1))
    else:
        # –û—Ü–µ–Ω–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        if 'llama3.3' in name_lower or 'llama3:latest' in name_lower:
            params_b = 70
        elif 'llama3:8b' in name_lower or 'qwen3:8b' in name_lower:
            params_b = 8
        elif 'llava' in name_lower and '34b' not in name_lower:
            params_b = 7  # llava:latest –æ–±—ã—á–Ω–æ 7b
        else:
            params_b = 7  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –º–∞–ª–µ–Ω—å–∫—É—é –º–æ–¥–µ–ª—å

    # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏ (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã * 2 –±–∞–π—Ç–∞ –¥–ª—è fp16 + –Ω–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã)
    estimated_ram_gb = (params_b * 2) // 1 + 2  # ~2GB –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä + 2GB overhead

    # –ü–æ–ª—É—á–∞–µ–º RAM —Å–∏—Å—Ç–µ–º—ã
    system_ram = get_system_memory_gb()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å (–æ—Å—Ç–∞–≤–ª—è–µ–º 16GB –¥–ª—è —Å–∏—Å—Ç–µ–º—ã)
    available_ram = system_ram - 16
    can_run = estimated_ram_gb <= available_ram

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if params_b >= 200:
        recommendation = "üî¥ –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è"
    elif params_b >= 70:
        if system_ram >= 128:
            recommendation = "üü° –ú–µ–¥–ª–µ–Ω–Ω–∞—è, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç"
        else:
            recommendation = "üî¥ –¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ RAM"
    elif params_b >= 30:
        recommendation = "üü¢ –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å"
    elif params_b >= 7:
        recommendation = "üü¢ –ë—ã—Å—Ç—Ä–∞—è"
    else:
        recommendation = "üü¢ –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è"

    return estimated_ram_gb, can_run, recommendation, params_b


def get_ollama_models() -> dict:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Ollama —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –∏ vision –º–æ–¥–µ–ª—è–º–∏.
    """
    result = {
        "text": [],           # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        "vision": [],         # –ú–æ–¥–µ–ª–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        "all": [],            # –í—Å–µ –º–æ–¥–µ–ª–∏
        "recommended": [],    # –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        "text_choices": [],   # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–ª—è Dropdown (—Ç–µ–∫—Å—Ç)
        "vision_choices": [], # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–ª—è Dropdown (vision)
        "system_ram": 0
    }

    if not LOCAL_AVAILABLE:
        return result

    try:
        client = OllamaClient()
        models = client.list_models()
        result["all"] = models
        result["system_ram"] = get_system_memory_gb()

        # Vision/OCR –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–º–æ–¥–µ–ª–∏, —Å–ø–æ—Å–æ–±–Ω—ã–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏)
        vision_keywords = [
            'llava', 'vision', 'bakllava', 'moondream', 'cogvlm',
            'qwen-vl', 'qwen3-vl', 'qwen2.5vl', 'qwen2-vl',  # Qwen Vision-Language
            'granite3.2-vision', 'granite-vision',            # IBM Granite OCR
            'deepseek-ocr', 'minicpm-v',                      # –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ OCR
            'llama3.2-vision', 'llama-vision'                 # Meta Vision
        ]

        # –ú–æ–¥–µ–ª–∏ —Å –ª—É—á—à–∏–º OCR (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º)
        ocr_optimized = ['granite3.2-vision', 'deepseek-ocr', 'qwen2.5vl', 'minicpm-v']

        # –§–∏–ª—å—Ç—Ä—É–µ–º –º–æ–¥–µ–ª–∏ —Å "-cloud" —Å—É—Ñ—Ñ–∏–∫—Å–æ–º (–æ–Ω–∏ —Ç—Ä–µ–±—É—é—Ç API –∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –ª–æ–∫–∞–ª—å–Ω–æ)
        cloud_keywords = ['-cloud', ':cloud', 'cloud-']

        for model in models:
            model_lower = model.lower()

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º "–æ–±–ª–∞—á–Ω—ã–µ" –º–æ–¥–µ–ª–∏ (—ç—Ç–æ –∑–∞–≥–ª—É—à–∫–∏, —Ç—Ä–µ–±—É—é—â–∏–µ –≤–Ω–µ—à–Ω–µ–≥–æ API)
            if any(kw in model_lower for kw in cloud_keywords):
                continue

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
            ram_gb, can_run, recommendation, params = estimate_model_size(model)

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            display_name = f"{model} {recommendation}"

            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ vision –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ
            is_vision = any(kw in model_lower for kw in vision_keywords)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å –¥–ª—è OCR
            is_ocr_optimized = any(kw in model_lower for kw in ocr_optimized)

            if is_vision:
                result["vision"].append(model)
                if can_run:
                    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É OCR –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                    if is_ocr_optimized:
                        display_name = f"‚≠ê {model} {recommendation} [OCR]"
                    # Gradio 5.x: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏ –Ω–∞–ø—Ä—è–º—É—é (display_name –≤–∫–ª—é—á–∞–µ—Ç model)
                    result["vision_choices"].append(display_name)
            else:
                result["text"].append(model)
                if can_run:
                    result["text_choices"].append(display_name)

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å
            if can_run and params <= 70 and "üü¢" in recommendation:
                result["recommended"].append(model)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ OCR-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (‚≠ê), –ø–æ—Ç–æ–º üü¢, –ø–æ—Ç–æ–º üü°
        def sort_key(display):
            if "‚≠ê" in display:      # OCR-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–≤—ã–º–∏
                return (0, display)
            elif "üü¢" in display:
                return (1, display)
            elif "üü°" in display:
                return (2, display)
            else:
                return (3, display)

        result["text_choices"].sort(key=sort_key)
        result["vision_choices"].sort(key=sort_key)

        return result
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π Ollama: {e}")
        return result


# ============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò PDF
# ============================================================================

def get_pdf_modes():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–∂–∏–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF."""
    return [
        ("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞", "extract_text"),
        ("–ö—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏", "summary"),
        ("–ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏", "key_concepts"),
        ("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ—É—á–∏–Ω–≥–∞", "coaching_tools"),
        ("–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏", "questions"),
        ("–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "full_analysis")
    ]


def process_pdf_file(
    pdf_file,
    mode: str,
    page_range: str,
    dpi: int,
    processing_mode: str = "cloud",  # "cloud" –∏–ª–∏ "local"
    ollama_model: str = None,        # –ú–æ–¥–µ–ª—å Ollama –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    progress=gr.Progress()
) -> Tuple[str, str, str]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç PDF —Ñ–∞–π–ª —á–µ—Ä–µ–∑ Vision API –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ.

    Args:
        processing_mode: "cloud" (Claude API) –∏–ª–∏ "local" (Ollama)
        ollama_model: –ú–æ–¥–µ–ª—å Ollama (llava:34b, llama3.3 –∏ —Ç.–¥.)

    Returns:
        Tuple[status, markdown_result, json_path]
    """
    if pdf_file is None:
        return "–ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF —Ñ–∞–π–ª", "", ""

    try:
        progress(0.05, desc="–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...")

        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (Gradio 5.x –ø–µ—Ä–µ–¥–∞—ë—Ç —Å—Ç—Ä–æ–∫—É)
        if isinstance(pdf_file, str):
            pdf_path = pdf_file
        elif hasattr(pdf_file, 'name'):
            pdf_path = pdf_file.name
        else:
            pdf_path = str(pdf_file)

        print(f"[GUI DEBUG] PDF path: {pdf_path}, mode: {processing_mode}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not Path(pdf_path).exists():
            return f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pdf_path}", "", ""

        # –õ–û–ö–ê–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê
        if processing_mode == "local":
            if not LOCAL_AVAILABLE:
                return "–û—à–∏–±–∫–∞: –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã", "", ""

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å (–∏–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –∏–∑ display_name)
            model_display = ollama_model or "llava:34b"
            model = extract_model_name(model_display)
            progress(0.1, desc=f"–°–æ–∑–¥–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ ({model})...")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ vision –º–æ–¥–µ–ª—å –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤–∞—è
            vision_keywords = [
                'llava', 'vision', 'bakllava', 'moondream', 'cogvlm',
                'qwen-vl', 'qwen3-vl', 'qwen2.5vl', 'qwen2-vl',
                'granite3.2-vision', 'granite-vision',
                'deepseek-ocr', 'minicpm-v',
                'llama3.2-vision', 'llama-vision'
            ]
            is_vision = any(kw in model.lower() for kw in vision_keywords)

            try:
                if is_vision:
                    processor = LocalVisionProcessor({"dpi": dpi, "vision_model": model})
                else:
                    # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º LocalPDFProcessor
                    processor = LocalPDFProcessor({"text_model": model})
            except ConnectionError as e:
                return f"–û—à–∏–±–∫–∞: {e}\n\n–ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama: ollama serve", "", ""

            # –ü–∞—Ä—Å–∏–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü (—Ç–æ–ª—å–∫–æ –¥–ª—è Vision –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞)
            page_tuple = None
            if page_range and page_range.strip():
                try:
                    start, end = validate_page_range(page_range)
                    page_tuple = (start, end)
                except ValueError as e:
                    return f"–û—à–∏–±–∫–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ —Å—Ç—Ä–∞–Ω–∏—Ü: {e}", "", ""

            progress(0.2, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ PDF...")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ (—Ä–∞–∑–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è Vision –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π)
            if is_vision:
                result = processor.process_pdf(pdf_path, mode=mode, page_range=page_tuple)
            else:
                # LocalPDFProcessor –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç page_range
                result = processor.process_pdf(pdf_path, mode=mode)

            # –ß–∏—Ç–∞–µ–º markdown —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            session_id = result["session_id"]
            md_path = OUTPUT_DIR / f"{session_id}_processed.md"
            json_path = OUTPUT_DIR / f"{session_id}_processed.json"

            md_content = ""
            if md_path.exists():
                with open(md_path, "r", encoding="utf-8") as f:
                    md_content = f.read()

            status = f"""‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!

üè† –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä: Ollama ({model})
üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
- –°—Ç—Ä–∞–Ω–∏—Ü: {result['total_pages']}
- –£—Å–ø–µ—à–Ω–æ: {result['successful_pages']}/{result['total_pages']}

üìÅ –§–∞–π–ª—ã:
- {md_path.name}
- {json_path.name}
"""
            progress(1.0, desc="–ì–æ—Ç–æ–≤–æ!")
            return status, md_content, str(json_path)

        # –û–ë–õ–ê–ß–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê (Claude API)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
        api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not api_key:
            return "–û—à–∏–±–∫–∞: ANTHROPIC_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env", "", ""

        progress(0.1, desc="–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ (Claude API)...")
        processor = PDFVisionProcessor(api_key=api_key)

        # –ü–∞—Ä—Å–∏–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü
        page_tuple = None
        if page_range and page_range.strip():
            try:
                start, end = validate_page_range(page_range)
                page_tuple = (start, end)
            except ValueError as e:
                return f"–û—à–∏–±–∫–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ —Å—Ç—Ä–∞–Ω–∏—Ü: {e}", "", ""

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º DPI (–Ω–∏–∂–µ = –±—ã—Å—Ç—Ä–µ–µ)
        processor.config["dpi"] = dpi
        print(f"[GUI DEBUG] DPI: {dpi}, mode: {mode}, page_range: {page_tuple}")

        progress(0.15, desc="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)...")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –ø–æ–∫–∞–∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        images = processor.pdf_to_images(pdf_path)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if page_tuple:
            start_page, end_page = page_tuple
            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å 0, page_tuple —Å 1
            images = images[start_page-1:end_page]
            print(f"[GUI DEBUG] Applied page range {page_tuple}: {len(images)} pages selected")
        total_pages = len(images)
        print(f"[GUI DEBUG] Converted {total_pages} pages to images")

        progress(0.3, desc=f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü. –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Claude...")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–º–µ—Ä –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–∏
        page_start = page_tuple[0] if page_tuple else 1

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ process_pages (–æ–Ω —Å–∞–º –¥–µ–ª–∞–µ—Ç –±–∞—Ç—á–∏–Ω–≥)
        print(f"[GUI DEBUG] Processing {total_pages} pages starting from {page_start}")
        progress(0.5, desc="–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü —á–µ—Ä–µ–∑ Claude Vision...")

        results = processor.process_pages(images, mode=mode, page_start=page_start)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
        total_tokens = {"input": 0, "output": 0}
        successful_results = []
        for r in results:
            if r.get("status") == "success":
                successful_results.append(r)
                total_tokens["input"] += r.get("usage", {}).get("input_tokens", 0)
                total_tokens["output"] += r.get("usage", {}).get("output_tokens", 0)

        progress(0.9, desc="–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        from datetime import datetime
        session_id = f"{Path(pdf_path).stem}_vision_{datetime.now().strftime('%H%M%S')}"

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        final_result = {
            "session_id": session_id,
            "source_pdf": pdf_path,
            "total_pages": total_pages,
            "mode": mode,
            "processed_at": datetime.now().isoformat(),
            "total_tokens": total_tokens,
            "results": results
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
        json_path = OUTPUT_DIR / f"{session_id}_processed.json"
        with open(json_path, "w", encoding="utf-8") as f:
            import json
            json.dump(final_result, f, ensure_ascii=False, indent=2)

        # –°–æ–∑–¥–∞—ë–º Markdown (–∏—Å–ø–æ–ª—å–∑—É–µ–º _save_as_markdown)
        md_path = OUTPUT_DIR / f"{session_id}_processed.md"
        processor._save_as_markdown(final_result, md_path)

        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        with open(md_path, "r", encoding="utf-8") as f:
            md_content = f.read()

        status = f"""‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!

üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
- –°—Ç—Ä–∞–Ω–∏—Ü: {total_pages}
- –£—Å–ø–µ—à–Ω—ã—Ö –±–∞—Ç—á–µ–π: {len(successful_results)}/{len(results)}
- –¢–æ–∫–µ–Ω–æ–≤: {total_tokens['input']:,} ‚Üí {total_tokens['output']:,}

üìÅ –§–∞–π–ª—ã:
- {md_path.name}
- {json_path.name}
"""

        progress(1.0, desc="–ì–æ—Ç–æ–≤–æ!")
        return status, md_content, str(json_path)

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[GUI ERROR] {error_details}")
        return f"‚ùå –û—à–∏–±–∫–∞: {str(e)}\n\n–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏", "", ""


def process_pdf_folder(
    folder_path: str,
    mode: str,
    dpi: int,
    progress=gr.Progress()
) -> str:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–∞–ø–∫—É —Å PDF —Ñ–∞–π–ª–∞–º–∏."""
    if not folder_path or not folder_path.strip():
        return "–£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ"

    folder = Path(folder_path)
    if not folder.exists():
        return f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}"

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ PDF
    pdf_files = list(folder.glob("*.pdf"))
    if not pdf_files:
        return f"PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {folder_path}"

    results = []
    total = len(pdf_files)

    for i, pdf_path in enumerate(pdf_files):
        progress((i + 1) / total, desc=f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {pdf_path.name}...")

        try:
            processor = PDFVisionProcessor()
            processor.config["dpi"] = dpi
            result = processor.process_pdf(str(pdf_path), mode=mode)

            results.append(f"‚úÖ {pdf_path.name}: {result['total_pages']} —Å—Ç—Ä, {result['total_tokens']['output']:,} —Ç–æ–∫–µ–Ω–æ–≤")
        except Exception as e:
            results.append(f"‚ùå {pdf_path.name}: {str(e)}")

    return f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total} —Ñ–∞–π–ª–æ–≤:\n\n" + "\n".join(results)


# ============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–ò –ê–£–î–ò–û
# ============================================================================

def _convert_to_mp3_if_needed(audio_path: str, progress_callback=None) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±–æ–ª—å—à–∏–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã –≤ MP3 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ MP3 —Ñ–∞–π–ª—É (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π).
    """
    from pydub import AudioSegment
    import re

    path = Path(audio_path)
    file_size_mb = path.stat().st_size / (1024 * 1024)

    # –ï—Å–ª–∏ —Ñ–∞–π–ª –º–∞–ª–µ–Ω—å–∫–∏–π –∏–ª–∏ —É–∂–µ MP3 - –Ω–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
    if file_size_mb < 25 or path.suffix.lower() == '.mp3':
        return audio_path

    print(f"   üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é {path.name} ({file_size_mb:.0f}MB) –≤ MP3...")

    # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π MP3 —Ñ–∞–π–ª
    mp3_path = OUTPUT_DIR / f"{path.stem}_converted.mp3"

    # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    try:
        duration_result = subprocess.run(
            ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',
             '-of', 'default=noprint_wrappers=1:nokey=1', str(path)],
            capture_output=True,
            text=True
        )
        total_duration = float(duration_result.stdout.strip())
    except:
        total_duration = None

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ ffmpeg —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    global _current_conversion_process
    try:
        print(f"   üéµ –ó–∞–ø—É—Å–∫–∞—é ffmpeg –¥–ª—è {path.name}...")

        process = subprocess.Popen(
            ['ffmpeg', '-y', '-i', str(path), '-vn', '-acodec', 'libmp3lame', '-q:a', '4', str(mp3_path)],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        _current_conversion_process = process  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ—Ç–º–µ–Ω—ã

        # –ß–∏—Ç–∞–µ–º stderr –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        while True:
            line = process.stderr.readline()
            if not line and process.poll() is not None:
                break

            if progress_callback and total_duration and 'time=' in line:
                # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è: time=00:01:23.45
                time_match = re.search(r'time=(\d{2}):(\d{2}):(\d{2})', line)
                if time_match:
                    h, m, s = map(int, time_match.groups())
                    current_time = h * 3600 + m * 60 + s
                    progress_pct = min(0.95, current_time / total_duration)
                    progress_callback(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: {int(progress_pct * 100)}%")

        process.wait()
        _current_conversion_process = None  # –û—á–∏—â–∞–µ–º –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è

        if process.returncode == 0 and mp3_path.exists():
            new_size = mp3_path.stat().st_size / (1024 * 1024)
            print(f"   ‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {new_size:.0f}MB")
            if progress_callback:
                progress_callback(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {new_size:.0f}MB")
            return str(mp3_path)
        else:
            stderr = process.stderr.read() if process.stderr else ""
            print(f"   ‚ùå ffmpeg –æ—à–∏–±–∫–∞ (–∫–æ–¥ {process.returncode}):\n{stderr[-500:]}")

    except Exception as e:
        print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ ffmpeg: {e}")
        _current_conversion_process = None

    # –ï—Å–ª–∏ ffmpeg –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º pydub
    try:
        if progress_callback:
            progress_callback("–ü—Ä–æ–±—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏...")
        audio = AudioSegment.from_file(str(path))
        audio.export(str(mp3_path), format="mp3")
        return str(mp3_path)
    except Exception as e:
        print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ pydub: {e}")
        return audio_path  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª


def cancel_audio_conversion():
    """–û—Ç–º–µ–Ω—è–µ—Ç —Ç–µ–∫—É—â—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –∞—É–¥–∏–æ."""
    global _current_conversion_process
    if _current_conversion_process and _current_conversion_process.poll() is None:
        _current_conversion_process.terminate()
        _current_conversion_process = None
        return "‚ùå –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º"
    return "‚ö†Ô∏è –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–º–µ–Ω—ã"


def transcribe_audio_file(
    audio_file,
    title: str,
    speaker: str,
    date: str,
    module: str,
    provider: str,
    transcript_only: bool,
    analysis_mode: str = "cloud",  # "cloud" –∏–ª–∏ "local" –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    analysis_model: str = None,    # –ú–æ–¥–µ–ª—å Ollama –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    progress=gr.Progress()
) -> Tuple[str, str, str]:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª.

    Args:
        provider: "openai", "local_whisper", "mlx_whisper"
        analysis_mode: "cloud" (Claude) –∏–ª–∏ "local" (Ollama) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
        analysis_model: –ú–æ–¥–µ–ª—å Ollama –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (llama3.3 –∏ —Ç.–¥.)

    Returns:
        Tuple[status, markdown_result, transcript_text]
    """
    if audio_file is None:
        return "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª", "", ""

    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ Radio (Gradio 5.x –ø–µ—Ä–µ–¥–∞—ë—Ç display-—Å—Ç—Ä–æ–∫–∏)
        provider = extract_radio_value(provider)
        analysis_mode = extract_radio_value(analysis_mode)

        progress(0.05, desc="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞...")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        if provider == "openai" and not os.environ.get("OPENAI_API_KEY"):
            return "–û—à–∏–±–∫–∞: OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω", "", ""

        if provider == "mlx_whisper" and not LOCAL_AVAILABLE:
            return "–û—à–∏–±–∫–∞: MLX-Whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. pip install mlx-whisper", "", ""

        if not transcript_only and analysis_mode == "cloud" and not os.environ.get("ANTHROPIC_API_KEY"):
            return "–û—à–∏–±–∫–∞: ANTHROPIC_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –æ–±–ª–∞—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", "", ""

        audio_path = audio_file.name if hasattr(audio_file, 'name') else audio_file

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
        file_size_mb = Path(audio_path).stat().st_size / (1024 * 1024)
        file_ext = Path(audio_path).suffix.lower()

        progress(0.1, desc=f"–§–∞–π–ª: {file_size_mb:.0f}MB ({file_ext})")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —ç–∫–∑–æ—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã (qta, avi, mov –∏ —Ç.–¥.) –∏–ª–∏ –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã
        STANDARD_FORMATS = ['.mp3', '.wav', '.m4a', '.ogg', '.flac']
        needs_conversion = (
            file_ext not in STANDARD_FORMATS or  # –≠–∫–∑–æ—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç
            file_size_mb > 25  # –ò–ª–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è API
        )

        if needs_conversion:
            progress(0.15, desc=f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é {file_ext} ({file_size_mb:.0f}MB) –≤ MP3...")
            audio_path = _convert_to_mp3_if_needed(
                audio_path,
                lambda msg: progress(0.2, desc=msg)
            )
            progress(0.25, desc="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {}
        if title:
            metadata["title"] = title
        if speaker:
            metadata["speaker"] = speaker
        if date:
            metadata["date"] = date
        if module:
            metadata["module"] = module

        if transcript_only:
            # –¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
            progress(0.3, desc="–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é –∞—É–¥–∏–æ...")

            # MLX-Whisper (–ª–æ–∫–∞–ª—å–Ω—ã–π)
            if provider == "mlx_whisper":
                transcriber = LocalWhisperTranscriber(model="large-v3")
                transcript = transcriber.transcribe(audio_path)
            else:
                transcriber = AudioTranscriber(provider=provider)
                transcript = transcriber.transcribe(audio_path)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
            output_name = Path(audio_path).stem
            transcript_path = TRANSCRIPTS_DIR / f"{output_name}_transcript.txt"
            with open(transcript_path, "w", encoding="utf-8") as f:
                f.write(transcript["text"])

            status = f"""‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!

‚è±Ô∏è –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {transcript['duration'] / 60:.1f} –º–∏–Ω
üìù –°–∏–º–≤–æ–ª–æ–≤: {len(transcript['text']):,}
üîß –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {provider}

üìÅ –§–∞–π–ª: {transcript_path.name}
"""
            return status, "", transcript["text"]

        else:
            # –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            progress(0.3, desc="–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (–±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã: 3-10 –º–∏–Ω)...")

            # MLX-Whisper (–ª–æ–∫–∞–ª—å–Ω—ã–π)
            if provider == "mlx_whisper":
                transcriber = LocalWhisperTranscriber(model="large-v3")
                transcript = transcriber.transcribe(audio_path)
            else:
                transcriber = AudioTranscriber(provider=provider)
                transcript = transcriber.transcribe(audio_path)

            # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
            if analysis_mode == "local":
                model_display = analysis_model or "llama3.3"
                model = extract_model_name(model_display)
                progress(0.5, desc=f"–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Ollama ({model})...")

                try:
                    client = OllamaClient()

                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä)
                    text_to_analyze = transcript['text'][:10000]

                    system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Å–µ–º–∏–Ω–∞—Ä–æ–≤ –∏ –ª–µ–∫—Ü–∏–π.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∏ —Å–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ."""

                    analysis_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å–µ–º–∏–Ω–∞—Ä–∞:

–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:
- –ù–∞–∑–≤–∞–Ω–∏–µ: {metadata.get('title', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
- –°–ø–∏–∫–µ—Ä: {metadata.get('speaker', '–ù–µ —É–∫–∞–∑–∞–Ω')}
- –î–∞—Ç–∞: {metadata.get('date', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:
{text_to_analyze}

–°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:
1. –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)
2. –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
3. –û—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏ —Å–ø–∏–∫–µ—Ä–∞
4. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
5. –í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""

                    analysis_result = client.generate(
                        model=model,
                        prompt=analysis_prompt,
                        system=system_prompt
                    )

                    results = {
                        "metadata": metadata,
                        "transcript": transcript,
                        "chunk_results": [],
                        "final_summary": f"# –ê–Ω–∞–ª–∏–∑ —Å–µ–º–∏–Ω–∞—Ä–∞\n\n**–ú–æ–¥–µ–ª—å:** {model}\n\n{analysis_result}",
                        "processed_at": datetime.now().isoformat(),
                        "model": model
                    }
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
                    results = {
                        "metadata": metadata,
                        "transcript": transcript,
                        "chunk_results": [],
                        "final_summary": f"# –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è\n\n‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}\n\n{transcript['text'][:5000]}...",
                        "processed_at": datetime.now().isoformat()
                    }
            else:
                progress(0.5, desc="–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Claude...")
                processor = SeminarProcessor()
                results = processor.process_seminar(transcript, metadata)

            progress(0.9, desc="–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ...")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if analysis_mode == "local":
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ –±–µ–∑ SeminarProcessor
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                title_clean = "".join(c for c in metadata.get('title', 'audio') if c.isalnum() or c in " _-")[:30]
                output_name = f"{title_clean}_{timestamp}"

                json_path = OUTPUT_DIR / f"{output_name}.json"
                with open(json_path, "w", encoding="utf-8") as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)

                md_path = OUTPUT_DIR / f"{output_name}.md"
                with open(md_path, "w", encoding="utf-8") as f:
                    f.write(results.get("final_summary", ""))

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
                transcript_path = TRANSCRIPTS_DIR / f"{output_name}_transcript.txt"
                with open(transcript_path, "w", encoding="utf-8") as f:
                    f.write(transcript.get("text", ""))
            else:
                json_path, md_path = processor.save_results(results)

            # –ß–∏—Ç–∞–µ–º Markdown
            md_content = ""
            if md_path.exists():
                with open(md_path, encoding="utf-8") as f:
                    md_content = f.read()

            status = f"""‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!

‚è±Ô∏è –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {transcript['duration'] / 60:.1f} –º–∏–Ω
üìù –°–∏–º–≤–æ–ª–æ–≤ –≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {len(transcript['text']):,}
üîß –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {provider}

üìÅ –§–∞–π–ª—ã:
- {md_path.name}
- {json_path.name}
"""

            progress(1.0, desc="–ì–æ—Ç–æ–≤–æ!")
            return status, md_content, transcript["text"]

    except Exception as e:
        import traceback
        return f"‚ùå –û—à–∏–±–∫–∞: {str(e)}\n\n{traceback.format_exc()}", "", ""


# ============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ü–†–û–°–ú–û–¢–†–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
# ============================================================================

def get_processed_files() -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."""
    files = []

    # JSON —Ñ–∞–π–ª—ã –∏–∑ output
    for f in OUTPUT_DIR.glob("*_processed.json"):
        files.append(f.name)

    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—ã
    for f in TRANSCRIPTS_DIR.glob("*.txt"):
        files.append(f"[transcripts] {f.name}")

    return sorted(files, reverse=True)


def load_processed_file(filename: str) -> Tuple[str, str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª."""
    if not filename:
        return "", ""

    try:
        if filename.startswith("[transcripts]"):
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
            actual_name = filename.replace("[transcripts] ", "")
            path = TRANSCRIPTS_DIR / actual_name
            with open(path, encoding="utf-8") as f:
                content = f.read()
            return content, ""

        else:
            # JSON + MD
            json_path = OUTPUT_DIR / filename
            md_path = json_path.with_suffix("").with_suffix(".md")

            md_content = ""
            json_content = ""

            if md_path.exists():
                with open(md_path, encoding="utf-8") as f:
                    md_content = f.read()

            if json_path.exists():
                with open(json_path, encoding="utf-8") as f:
                    data = json.load(f)
                    json_content = json.dumps(data, ensure_ascii=False, indent=2)

            return md_content, json_content

    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {e}", ""


def refresh_file_list():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤."""
    return gr.Dropdown(choices=get_processed_files())


def search_in_results(query: str) -> str:
    """–ü–æ–∏—Å–∫ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º."""
    if not query or len(query) < 2:
        return "–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–º–∏–Ω–∏–º—É–º 2 —Å–∏–º–≤–æ–ª–∞)"

    results = []
    query_lower = query.lower()

    # –ü–æ–∏—Å–∫ –≤ markdown —Ñ–∞–π–ª–∞—Ö
    for md_file in OUTPUT_DIR.glob("*_processed.md"):
        try:
            with open(md_file, encoding="utf-8") as f:
                content = f.read()

            if query_lower in content.lower():
                # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                idx = content.lower().find(query_lower)
                start = max(0, idx - 100)
                end = min(len(content), idx + 200)
                snippet = content[start:end].replace("\n", " ")

                results.append(f"### {md_file.name}\n\n...{snippet}...\n")
        except Exception:
            continue

    # –ü–æ–∏—Å–∫ –≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞—Ö
    for txt_file in TRANSCRIPTS_DIR.glob("*.txt"):
        try:
            with open(txt_file, encoding="utf-8") as f:
                content = f.read()

            if query_lower in content.lower():
                idx = content.lower().find(query_lower)
                start = max(0, idx - 100)
                end = min(len(content), idx + 200)
                snippet = content[start:end].replace("\n", " ")

                results.append(f"### [transcript] {txt_file.name}\n\n...{snippet}...\n")
        except Exception:
            continue

    if results:
        return f"–ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\n\n" + "\n---\n".join(results)
    else:
        return f"–ü–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"


# ============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ù–ê–°–¢–†–û–ï–ö
# ============================================================================

def check_api_keys() -> str:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–µ–π (–±–µ–∑–æ–ø–∞—Å–Ω–æ, –±–µ–∑ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –∑–Ω–∞—á–µ–Ω–∏–π)."""
    keys_info = utils_check_api_keys()
    status = []

    for key_name, info in keys_info.items():
        if info["present"]:
            status.append(f"‚úÖ {key_name}: {info['masked']}")
        else:
            status.append(f"‚ùå {key_name}: –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    return "\n".join(status)


def get_stats() -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
    pdf_count = len(list(OUTPUT_DIR.glob("*_processed.json")))
    transcript_count = len(list(TRANSCRIPTS_DIR.glob("*.txt")))

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
    total_input = 0
    total_output = 0

    for json_file in OUTPUT_DIR.glob("*_processed.json"):
        try:
            with open(json_file, encoding="utf-8") as f:
                data = json.load(f)
            total_input += data.get("total_tokens", {}).get("input", 0)
            total_output += data.get("total_tokens", {}).get("output", 0)
        except Exception:
            continue

    return f"""üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:

üìÑ PDF –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {pdf_count}
üéôÔ∏è –ê—É–¥–∏–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–æ: {transcript_count}

üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤:
- –í—Ö–æ–¥—è—â–∏—Ö: {total_input:,}
- –ò—Å—Ö–æ–¥—è—â–∏—Ö: {total_output:,}
- –í—Å–µ–≥–æ: {total_input + total_output:,}

üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:
- Output: {OUTPUT_DIR}
- Transcripts: {TRANSCRIPTS_DIR}
"""


# ============================================================================
# –°–û–ó–î–ê–ù–ò–ï –ò–ù–¢–ï–†–§–ï–ô–°–ê
# ============================================================================

def extract_model_name(display_name: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ display_name (–Ω–∞–ø—Ä–∏–º–µ—Ä, '‚≠ê qwen2.5vl:7b üü¢ ...' -> 'qwen2.5vl:7b')."""
    # –£–±–∏—Ä–∞–µ–º ‚≠ê –∏ [OCR] –µ—Å–ª–∏ –µ—Å—Ç—å
    name = display_name.replace("‚≠ê ", "").replace(" [OCR]", "")
    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –¥–æ üü¢/üü°/üî¥
    for marker in ["üü¢", "üü°", "üî¥"]:
        if marker in name:
            name = name.split(marker)[0].strip()
            break
    return name.strip()


def extract_radio_value(display_value: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ Radio choice (–Ω–∞–ø—Ä–∏–º–µ—Ä, '‚òÅÔ∏è OpenAI (openai)' -> 'openai')."""
    if "(" in display_value and ")" in display_value:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —Å–∫–æ–±–∫–∞—Ö
        value = display_value.split("(")[1].split(")")[0].strip()
        return value
    # –ï—Å–ª–∏ —Å–∫–æ–±–æ–∫ –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    return display_value.strip()


def create_interface():
    """–°–æ–∑–¥–∞–µ—Ç Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å."""

    # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ Ollama –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    ollama_models = get_ollama_models()

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ choices —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ (—Å—Ç—Ä–æ–∫–∏ –¥–ª—è Gradio 5.x)
    vision_choices = ollama_models["vision_choices"] if ollama_models["vision_choices"] else ["llava:34b üü¢ –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å"]
    text_choices = ollama_models["text_choices"] if ollama_models["text_choices"] else ["llama3.3 üü° –ú–µ–¥–ª–µ–Ω–Ω–∞—è, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç"]

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ (vision –ø–µ—Ä–≤—ã–µ, –ø–æ—Ç–æ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ)
    all_model_choices = vision_choices + text_choices

    # –î–ª—è PDF –∏ Audio –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å–ø–∏—Å–æ–∫
    pdf_model_choices = all_model_choices
    audio_model_choices = all_model_choices  # –û–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å PDF –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏

    # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞)
    default_vision = vision_choices[0] if vision_choices else "llava:34b üü¢ –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å"
    default_text = text_choices[0] if text_choices else "llama3.3 üü° –ú–µ–¥–ª–µ–Ω–Ω–∞—è, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç"

    # RAM —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    system_ram = ollama_models.get("system_ram", 0)

    # CSS –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è Dropdown —Å –ø—Ä–æ–∫—Ä—É—Ç–∫–æ–π
    custom_css = """
    /* –§–∏–∫—Å –ø—Ä–æ–∫—Ä—É—Ç–∫–∏ –¥–ª—è dropdown —Å–ø–∏—Å–∫–æ–≤ Ollama –º–æ–¥–µ–ª–µ–π */
    .dropdown-container ul {
        max-height: 300px !important;
        overflow-y: auto !important;
    }
    /* –£–ª—É—á—à–µ–Ω–Ω—ã–π scrollbar */
    .dropdown-container ul::-webkit-scrollbar {
        width: 8px;
    }
    .dropdown-container ul::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 4px;
    }
    .dropdown-container ul::-webkit-scrollbar-thumb {
        background: #888;
        border-radius: 4px;
    }
    .dropdown-container ul::-webkit-scrollbar-thumb:hover {
        background: #555;
    }
    """

    with gr.Blocks(title="SKOLKOVO Materials Processor", css=custom_css) as app:

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        gr.Markdown("""
        # üìö SKOLKOVO Materials Processor

        **–°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º—ã Executive Coaching & Mentoring**

        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–π—Ç–µ PDF –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–π—Ç–µ –∞—É–¥–∏–æ –∑–∞–ø–∏—Å–∏, –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
        """, elem_classes="main-header")

        with gr.Tabs():

            # ========================
            # TAB 1: PDF –û–ë–†–ê–ë–û–¢–ö–ê
            # ========================
            with gr.Tab("üìÑ PDF –û–±—Ä–∞–±–æ—Ç–∫–∞"):
                gr.Markdown("### –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF —á–µ—Ä–µ–∑ Claude Vision –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ (Ollama)")

                with gr.Row():
                    with gr.Column(scale=1):
                        pdf_file = gr.File(
                            label="PDF —Ñ–∞–π–ª",
                            file_types=[".pdf"],
                            type="filepath"
                        )

                        # –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å –æ–±–ª–∞–∫–æ/–ª–æ–∫–∞–ª—å–Ω–æ
                        pdf_processing_mode = gr.Radio(
                            label="üîß –†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏",
                            choices=[
                                ("‚òÅÔ∏è –û–±–ª–∞–∫–æ (Claude API)", "cloud"),
                                ("üè† –õ–æ–∫–∞–ª—å–Ω–æ (Ollama)", "local")
                            ],
                            value="cloud",
                            info="–û–±–ª–∞–∫–æ: –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –ø–ª–∞—Ç–Ω–æ | –õ–æ–∫–∞–ª—å–Ω–æ: –±–µ—Å–ø–ª–∞—Ç–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç Ollama"
                        )

                        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ Ollama –¥–ª—è PDF (vision)
                        with gr.Row():
                            pdf_ollama_model = gr.Dropdown(
                                label="ü§ñ –ú–æ–¥–µ–ª—å Ollama",
                                choices=pdf_model_choices,
                                value=default_vision,
                                visible=False,  # –°–∫—Ä—ã—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –≤—ã–±–æ—Ä–µ local)
                                info=f"RAM: {system_ram}GB | ‚≠ê OCR | üü¢ –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ | üü° –ú–µ–¥–ª–µ–Ω–Ω–∞—è",
                                scale=4
                            )
                            pdf_refresh_models = gr.Button(
                                "üîÑ",
                                visible=False,
                                scale=1,
                                min_width=50
                            )

                        # –§—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π PDF (vision + text)
                        def refresh_pdf_models():
                            """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è PDF."""
                            models = get_ollama_models()
                            vision = models["vision_choices"] if models["vision_choices"] else ["llava:34b üü¢"]
                            text = models["text_choices"] if models["text_choices"] else ["llama3.3 üü°"]
                            pdf_choices = vision + text
                            default_v = vision[0] if vision else "llava:34b"
                            return gr.update(choices=pdf_choices, value=default_v)

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º/—Å–∫—Ä—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å–º–µ–Ω–µ —Ä–µ–∂–∏–º–∞
                        def toggle_model_visibility(mode):
                            visible = (mode == "local")
                            return gr.update(visible=visible), gr.update(visible=visible)

                        pdf_processing_mode.change(
                            fn=toggle_model_visibility,
                            inputs=[pdf_processing_mode],
                            outputs=[pdf_ollama_model, pdf_refresh_models]
                        )

                        pdf_mode = gr.Dropdown(
                            label="–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞",
                            choices=[m[0] for m in get_pdf_modes()],
                            value="–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
                            info="–í—ã–±–µ—Ä–∏—Ç–µ –≥–ª—É–±–∏–Ω—É –∞–Ω–∞–ª–∏–∑–∞"
                        )

                        with gr.Row():
                            pdf_pages = gr.Textbox(
                                label="–°—Ç—Ä–∞–Ω–∏—Ü—ã",
                                placeholder="1-10 –∏–ª–∏ –ø—É—Å—Ç–æ –¥–ª—è –≤—Å–µ—Ö",
                                scale=1
                            )
                            pdf_dpi = gr.Slider(
                                label="DPI",
                                minimum=72,
                                maximum=300,
                                value=150,
                                step=10,
                                scale=1
                            )

                        pdf_btn = gr.Button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å PDF", variant="primary")

                    with gr.Column(scale=2):
                        pdf_status = gr.Textbox(
                            label="–°—Ç–∞—Ç—É—Å",
                            lines=8,
                            interactive=False
                        )
                        pdf_json_path = gr.Textbox(
                            label="–ü—É—Ç—å –∫ JSON",
                            visible=False
                        )

                pdf_result = gr.Markdown(
                    label="–†–µ–∑—É–ª—å—Ç–∞—Ç",
                    value="*–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏*"
                )

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏
                gr.Markdown("---\n### –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏")

                with gr.Row():
                    folder_path = gr.Textbox(
                        label="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ",
                        placeholder="/Users/.../Documents/PDFs",
                        scale=3
                    )
                    folder_btn = gr.Button("üìÅ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–∞–ø–∫—É", scale=1)

                folder_result = gr.Textbox(
                    label="–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏",
                    lines=10,
                    interactive=False
                )

                # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏–∏
                def get_mode_key(mode_name):
                    modes = dict(get_pdf_modes())
                    for name, key in get_pdf_modes():
                        if name == mode_name:
                            return key
                    return "full_analysis"

                pdf_btn.click(
                    fn=lambda f, m, p, d, pm, om: process_pdf_file(f, get_mode_key(m), p, d, pm, om),
                    inputs=[pdf_file, pdf_mode, pdf_pages, pdf_dpi, pdf_processing_mode, pdf_ollama_model],
                    outputs=[pdf_status, pdf_result, pdf_json_path]
                )

                folder_btn.click(
                    fn=lambda p, m, d: process_pdf_folder(p, get_mode_key(m), d),
                    inputs=[folder_path, pdf_mode, pdf_dpi],
                    outputs=[folder_result]
                )

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π PDF
                pdf_refresh_models.click(
                    fn=refresh_pdf_models,
                    outputs=[pdf_ollama_model]
                )

            # ========================
            # TAB 2: –ê–£–î–ò–û –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø
            # ========================
            with gr.Tab("üéôÔ∏è –ê—É–¥–∏–æ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è"):
                gr.Markdown("### –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ + –∞–Ω–∞–ª–∏–∑ (–æ–±–ª–∞–∫–æ –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ)")

                with gr.Row():
                    with gr.Column(scale=1):
                        audio_file = gr.File(
                            label="–ê—É–¥–∏–æ —Ñ–∞–π–ª",
                            file_types=[".mp3", ".m4a", ".wav", ".mp4", ".webm", ".ogg", ".flac", ".qta"],
                            type="filepath"
                        )

                        audio_title = gr.Textbox(
                            label="–ù–∞–∑–≤–∞–Ω–∏–µ",
                            placeholder="–°–µ–º–∏–Ω–∞—Ä –ø–æ –∫–æ—É—á–∏–Ω–≥—É"
                        )

                        audio_speaker = gr.Textbox(
                            label="–°–ø–∏–∫–µ—Ä",
                            placeholder="–ï–ª–µ–Ω–∞ –ö–ª–µ–∫–æ–≤–∫–∏–Ω–∞"
                        )

                        with gr.Row():
                            audio_date = gr.Textbox(
                                label="–î–∞—Ç–∞",
                                placeholder="2025-11-25",
                                scale=1
                            )
                            audio_module = gr.Textbox(
                                label="–ú–æ–¥—É–ª—å",
                                placeholder="1",
                                scale=1
                            )

                        # –ü—Ä–æ–≤–∞–π–¥–µ—Ä —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å MLX
                        audio_provider = gr.Radio(
                            label="üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è",
                            choices=["‚òÅÔ∏è OpenAI Whisper (openai)", "üè† MLX-Whisper (mlx_whisper)"],
                            value="‚òÅÔ∏è OpenAI Whisper (openai)",
                            info="OpenAI: –ø–ª–∞—Ç–Ω–æ, –±—ã—Å—Ç—Ä–æ | MLX-Whisper: –±–µ—Å–ø–ª–∞—Ç–Ω–æ, –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ Mac"
                        )

                        # –†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞
                        audio_analysis_mode = gr.Radio(
                            label="üìä –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞",
                            choices=["‚òÅÔ∏è Claude API (cloud)", "üè† Ollama (local)"],
                            value="‚òÅÔ∏è Claude API (cloud)",
                            info="Claude: –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ | Ollama: –±—ã—Å—Ç—Ä—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
                        )

                        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ Ollama –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞—É–¥–∏–æ
                        with gr.Row():
                            audio_ollama_model = gr.Dropdown(
                                label="ü§ñ –ú–æ–¥–µ–ª—å Ollama (–∞–Ω–∞–ª–∏–∑)",
                                choices=audio_model_choices,
                                value=default_text,
                                visible=False,
                                info=f"RAM: {system_ram}GB | üü¢ –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ | üü° –ú–µ–¥–ª–µ–Ω–Ω–∞—è",
                                scale=4
                            )
                            audio_refresh_models = gr.Button(
                                "üîÑ",
                                visible=False,
                                scale=1,
                                min_width=50
                            )

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º/—Å–∫—Ä—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å–º–µ–Ω–µ —Ä–µ–∂–∏–º–∞ –∞–Ω–∞–ª–∏–∑–∞
                        def toggle_audio_model_visibility(mode):
                            mode_value = extract_radio_value(mode)
                            visible = (mode_value == "local")
                            return gr.update(visible=visible), gr.update(visible=visible)

                        audio_analysis_mode.change(
                            fn=toggle_audio_model_visibility,
                            inputs=[audio_analysis_mode],
                            outputs=[audio_ollama_model, audio_refresh_models]
                        )

                        audio_only = gr.Checkbox(
                            label="–¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (–±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞)",
                            value=False
                        )

                        with gr.Row():
                            audio_btn = gr.Button("üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å", variant="primary", scale=3)
                            audio_cancel_btn = gr.Button("‚ùå –û—Ç–º–µ–Ω–∏—Ç—å", variant="stop", scale=1)

                    with gr.Column(scale=2):
                        audio_status = gr.Textbox(
                            label="–°—Ç–∞—Ç—É—Å",
                            lines=10,
                            interactive=False
                        )

                with gr.Tabs():
                    with gr.Tab("–ê–Ω–∞–ª–∏–∑"):
                        audio_result = gr.Markdown(
                            label="–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞",
                            value="*–ê–Ω–∞–ª–∏–∑ –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å*"
                        )

                    with gr.Tab("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç"):
                        audio_transcript = gr.Textbox(
                            label="–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç",
                            lines=20,
                            interactive=False
                        )

                audio_btn.click(
                    fn=transcribe_audio_file,
                    inputs=[audio_file, audio_title, audio_speaker, audio_date, audio_module, audio_provider, audio_only, audio_analysis_mode, audio_ollama_model],
                    outputs=[audio_status, audio_result, audio_transcript]
                )

                # –ö–Ω–æ–ø–∫–∞ –æ—Ç–º–µ–Ω—ã –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
                audio_cancel_btn.click(
                    fn=cancel_audio_conversion,
                    outputs=[audio_status]
                )

                # –§—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π Audio (–≤—Å–µ –º–æ–¥–µ–ª–∏, –∫–∞–∫ –¥–ª—è PDF)
                def refresh_audio_models():
                    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞—É–¥–∏–æ (–≤—Å–µ –º–æ–¥–µ–ª–∏, –∫–∞–∫ –¥–ª—è PDF)."""
                    models = get_ollama_models()
                    vision = models["vision_choices"] if models["vision_choices"] else []
                    text = models["text_choices"] if models["text_choices"] else ["llama3.3 üü°"]
                    all_models = vision + text  # –û–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ —Å PDF
                    default_m = all_models[0] if all_models else "llama3.3"
                    return gr.update(choices=all_models, value=default_m)

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π Audio
                audio_refresh_models.click(
                    fn=refresh_audio_models,
                    outputs=[audio_ollama_model]
                )

            # ========================
            # TAB 3: –ü–†–û–°–ú–û–¢–† –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
            # ========================
            with gr.Tab("üìñ –ü—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"):
                gr.Markdown("### –ü—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤")

                with gr.Row():
                    file_dropdown = gr.Dropdown(
                        label="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª",
                        choices=get_processed_files(),
                        scale=3
                    )
                    refresh_btn = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", scale=1)

                with gr.Tabs():
                    with gr.Tab("Markdown"):
                        result_md = gr.Markdown(
                            label="–°–æ–¥–µ—Ä–∂–∏–º–æ–µ",
                            value="*–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞*"
                        )

                    with gr.Tab("JSON"):
                        result_json = gr.Code(
                            label="JSON –¥–∞–Ω–Ω—ã–µ",
                            language="json"
                        )

                gr.Markdown("---\n### –ü–æ–∏—Å–∫ –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º")

                with gr.Row():
                    search_query = gr.Textbox(
                        label="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å",
                        placeholder="–∫–æ—É—á–∏–Ω–≥, —Ä–µ—Ñ–ª–µ–∫—Å–∏—è, –ª–∏–¥–µ—Ä—Å—Ç–≤–æ...",
                        scale=3
                    )
                    search_btn = gr.Button("üîç –ò—Å–∫–∞—Ç—å", scale=1)

                search_result = gr.Markdown(
                    label="–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞"
                )

                file_dropdown.change(
                    fn=load_processed_file,
                    inputs=[file_dropdown],
                    outputs=[result_md, result_json]
                )

                refresh_btn.click(
                    fn=lambda: gr.Dropdown(choices=get_processed_files()),
                    outputs=[file_dropdown]
                )

                search_btn.click(
                    fn=search_in_results,
                    inputs=[search_query],
                    outputs=[search_result]
                )

            # ========================
            # TAB 4: –ù–ê–°–¢–†–û–ô–ö–ò
            # ========================
            with gr.Tab("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏"):
                gr.Markdown("### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

                with gr.Row():
                    with gr.Column():
                        gr.Markdown("#### ‚òÅÔ∏è –û–±–ª–∞—á–Ω—ã–µ API")
                        api_status = gr.Textbox(
                            label="–°—Ç–∞—Ç—É—Å API –∫–ª—é—á–µ–π",
                            value=check_api_keys(),
                            lines=4,
                            interactive=False
                        )

                        check_api_btn = gr.Button("üîë –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–ª—é—á–∏")
                        check_api_btn.click(
                            fn=check_api_keys,
                            outputs=[api_status]
                        )

                        gr.Markdown("""
                        **–ö–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á–∏:**

                        –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ —Ñ–∞–π–ª `.env` –≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞:
                        ```
                        ANTHROPIC_API_KEY=sk-ant-...
                        OPENAI_API_KEY=sk-...
                        ```
                        """)

                        gr.Markdown("#### üè† –õ–æ–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã")

                        def check_local_status():
                            if not LOCAL_AVAILABLE:
                                return "‚ùå –õ–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"
                            try:
                                status = check_local_requirements()
                                lines = []
                                lines.append(f"Ollama: {'‚úÖ –ó–∞–ø—É—â–µ–Ω' if status['ollama'] else '‚ùå –ù–µ –∑–∞–ø—É—â–µ–Ω (ollama serve)'}")
                                if status['ollama'] and status['ollama_models']:
                                    all_models = status['ollama_models']

                                    # –†–∞–∑–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª–∏
                                    vision_kw = ['llava', 'vision', 'bakllava', 'moondream', 'cogvlm', 'qwen-vl', 'qwen3-vl']
                                    vision_m = [m for m in all_models if any(kw in m.lower() for kw in vision_kw)]
                                    text_m = [m for m in all_models if m not in vision_m]

                                    lines.append(f"\nüìù –¢–µ–∫—Å—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ ({len(text_m)}):")
                                    for m in text_m[:8]:
                                        lines.append(f"   ‚Ä¢ {m}")
                                    if len(text_m) > 8:
                                        lines.append(f"   ... –∏ –µ—â—ë {len(text_m) - 8}")

                                    lines.append(f"\nüñºÔ∏è Vision –º–æ–¥–µ–ª–∏ ({len(vision_m)}):")
                                    if vision_m:
                                        for m in vision_m:
                                            lines.append(f"   ‚Ä¢ {m}")
                                    else:
                                        lines.append("   ‚ö†Ô∏è –ù–µ—Ç (ollama pull llava:34b)")

                                lines.append(f"\nMLX-Whisper: {'‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if status['mlx_whisper'] else '‚ùå –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}")
                                lines.append(f"pdf2image: {'‚úÖ' if status['pdf2image'] else '‚ùå'}")
                                return "\n".join(lines)
                            except Exception as e:
                                return f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}"

                        local_status = gr.Textbox(
                            label="–°—Ç–∞—Ç—É—Å –ª–æ–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤",
                            value=check_local_status() if LOCAL_AVAILABLE else "–õ–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã",
                            lines=6,
                            interactive=False
                        )

                        check_local_btn = gr.Button("üîÑ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ")
                        check_local_btn.click(
                            fn=check_local_status,
                            outputs=[local_status]
                        )

                        gr.Markdown("""
                        **–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:**
                        ```bash
                        # Ollama
                        brew install ollama
                        ollama serve  # –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
                        ollama pull llama3.3      # —Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å
                        ollama pull llava:34b     # vision –º–æ–¥–µ–ª—å

                        # MLX-Whisper (—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è)
                        pip install mlx-whisper
                        ```
                        """)

                    with gr.Column():
                        gr.Markdown("#### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                        stats = gr.Textbox(
                            label="–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
                            value=get_stats(),
                            lines=12,
                            interactive=False
                        )

                        refresh_stats_btn = gr.Button("üìä –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")
                        refresh_stats_btn.click(
                            fn=get_stats,
                            outputs=[stats]
                        )

        # –§—É—Ç–µ—Ä
        gr.Markdown("""
        ---

        **SKOLKOVO Materials Processor** | Executive Coaching & Mentoring Program

        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
        - PDF: –æ–±—ã—á–Ω—ã–µ, —Å–∫–∞–Ω—ã, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ (—á–µ—Ä–µ–∑ Claude Vision)
        - –ê—É–¥–∏–æ: MP3, M4A, WAV, MP4, WEBM, OGG, FLAC, QTA
        """)

    return app


# ============================================================================
# –ó–ê–ü–£–°–ö
# ============================================================================

if __name__ == "__main__":
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë     üìö SKOLKOVO Materials Processor - GUI                    ‚ïë
‚ïë                                                              ‚ïë
‚ïë     –û—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è –≤ –±—Ä–∞—É–∑–µ—Ä–µ: http://localhost:7860            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
""")

    app = create_interface()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True
    )
