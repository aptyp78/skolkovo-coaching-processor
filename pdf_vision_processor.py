#!/usr/bin/env python3
"""
PDF Vision Processor Ğ´Ğ»Ñ SKOLKOVO Executive Coaching Program
=============================================================
Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ PDF Ñ‡ĞµÑ€ĞµĞ· Claude Vision API.
ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ PDF Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· Claude.

ĞŸÑ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ°:
- Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ Ğ»ÑĞ±Ñ‹Ğ¼ PDF (ÑĞºĞ°Ğ½Ñ‹, Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸, Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹)
- Ğ•Ğ´Ğ¸Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ñ‚Ğ¸Ğ¿Ğ¾Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°
- Ğ’Ñ‹ÑĞ¾ĞºĞ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
    python pdf_vision_processor.py process Ñ„Ğ°Ğ¹Ğ».pdf
    python pdf_vision_processor.py process Ñ„Ğ°Ğ¹Ğ».pdf --mode full_analysis
"""

import os
import sys
import json
import base64
import hashlib
import tempfile
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import argparse
from io import BytesIO

# PDF to image conversion
try:
    from pdf2image import convert_from_path
    from PIL import Image
    PDF2IMAGE_AVAILABLE = True
except ImportError:
    PDF2IMAGE_AVAILABLE = False
    print("âš ï¸ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ: pip install pdf2image pillow")

# Claude API
try:
    import anthropic
except ImportError:
    print("Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ anthropic: pip install anthropic")
    sys.exit(1)


# ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
DEFAULT_CONFIG = {
    "model": "claude-sonnet-4-20250514",
    "max_output_tokens": 4096,
    "language": "ru",
    "dpi": 150,  # Ğ Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸ PDF -> Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
    "max_pages_per_request": 4,  # ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ Ğº Claude
    "processing_modes": {
        "extract_text": "Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ Ğ²ĞµÑÑŒ Ñ‚ĞµĞºÑÑ‚ ÑĞ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ",
        "summary": "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ ÑĞ°Ğ¼Ğ¼Ğ°Ñ€Ğ¸",
        "key_concepts": "Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
        "coaching_tools": "Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ ĞºĞ¾ÑƒÑ‡Ğ¸Ğ½Ğ³Ğ°",
        "questions": "Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸",
        "full_analysis": "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·: Ñ‚ĞµĞºÑÑ‚ + ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸ + Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ + Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹"
    }
}


class PDFVisionProcessor:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° PDF Ñ‡ĞµÑ€ĞµĞ· Claude Vision API."""

    def __init__(self, api_key: str = None, config: dict = None):
        """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°."""
        self.api_key = api_key or os.environ.get("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError("API ĞºĞ»ÑÑ‡ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ ANTHROPIC_API_KEY")

        if not PDF2IMAGE_AVAILABLE:
            raise ImportError("Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ pdf2image: pip install pdf2image pillow")

        self.client = anthropic.Anthropic(api_key=self.api_key)
        self.config = {**DEFAULT_CONFIG, **(config or {})}

        # ĞŸÑƒÑ‚Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ
        self.base_dir = Path(__file__).parent
        self.output_dir = self.base_dir / "output"
        self.output_dir.mkdir(exist_ok=True)

    def pdf_to_images(self, pdf_path: str, dpi: int = None) -> List[Image.Image]:
        """
        ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ PDF Ğ² ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹.

        Args:
            pdf_path: ĞŸÑƒÑ‚ÑŒ Ğº PDF Ñ„Ğ°Ğ¹Ğ»Ñƒ
            dpi: Ğ Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ· ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ°)

        Returns:
            List[Image.Image]: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº PIL Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
        """
        dpi = dpi or self.config["dpi"]
        pdf_path = Path(pdf_path)

        if not pdf_path.exists():
            raise FileNotFoundError(f"PDF Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {pdf_path}")

        print(f"ğŸ“„ ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒÑ PDF Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ: {pdf_path.name}")
        print(f"   DPI: {dpi}")

        images = convert_from_path(str(pdf_path), dpi=dpi)

        print(f"   âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ {len(images)} ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†")

        return images

    def image_to_base64(self, image: Image.Image, format: str = "PNG", max_size: int = 1568) -> str:
        """
        ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ PIL Image Ğ² base64 ÑÑ‚Ñ€Ğ¾ĞºÑƒ.

        Args:
            image: PIL Image
            format: Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
            max_size: ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹ (Claude Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ)

        Returns:
            str: Base64 encoded string
        """
        # Ğ ĞµÑĞ°Ğ¹Ğ·Ğ¸Ğ¼ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ (Claude Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ ~1568px Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹)
        if max(image.size) > max_size:
            ratio = max_size / max(image.size)
            new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
            image = image.resize(new_size, Image.Resampling.LANCZOS)

        buffer = BytesIO()
        image.save(buffer, format=format)
        return base64.standard_b64encode(buffer.getvalue()).decode("utf-8")

    def get_system_prompt(self, mode: str) -> str:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸."""

        base_prompt = """Ğ¢Ñ‹ - AI-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Executive Coaching & Mentoring Ğ² Ğ¡ĞšĞĞ›ĞšĞĞ’Ğ.
ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† PDF Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¸ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ.

Ğ’ĞĞ–ĞĞ:
1. Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°Ğ¹ Ğ’Ğ¡Ğ• Ğ²Ğ¸Ğ´Ğ¸Ğ¼Ñ‹Ğµ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹: Ñ‚ĞµĞºÑÑ‚, Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹, ÑÑ…ĞµĞ¼Ñ‹, Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸
2. ĞĞ¿Ğ¸ÑÑ‹Ğ²Ğ°Ğ¹ Ğ´Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼
3. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°
4. Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ¹, ĞµÑĞ»Ğ¸ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ½ĞµÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ğ¾ Ğ¸Ğ»Ğ¸ Ğ½ĞµÑÑĞ½Ğ¾

ĞšĞĞĞ¢Ğ•ĞšĞ¡Ğ¢ ĞŸĞ ĞĞ“Ğ ĞĞœĞœĞ«:
- Executive-ĞºĞ¾ÑƒÑ‡Ğ¸Ğ½Ğ³ Ğ¸ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ Ğ»Ğ¸Ğ´ĞµÑ€ÑÑ‚Ğ²Ğ°
- ĞŸÑĞ¸Ñ…Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸
- Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸ ĞºĞ¾ÑƒÑ‡Ğ¸Ğ½Ğ³Ğ°

"""

        mode_prompts = {
            "extract_text": """Ğ—ĞĞ”ĞĞ§Ğ: Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ Ğ²ĞµÑÑŒ Ñ‚ĞµĞºÑÑ‚ ÑĞ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞ¹ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ (Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸, ÑĞ¿Ğ¸ÑĞºĞ¸, Ğ°Ğ±Ğ·Ğ°Ñ†Ñ‹)
- Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞ¹ Ğ² markdown Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ
- ĞĞ¿Ğ¸ÑÑ‹Ğ²Ğ°Ğ¹ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¸ ÑÑ…ĞµĞ¼Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ [Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ•: Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ]
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞ¹ Ğ½ÑƒĞ¼ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¼Ğ°Ñ€ĞºĞ¸Ñ€Ğ¾Ğ²ĞºÑƒ
""",

            "summary": """Ğ—ĞĞ”ĞĞ§Ğ: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ ÑĞ°Ğ¼Ğ¼Ğ°Ñ€Ğ¸

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:
## ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ñ‚ĞµĞ¼Ñ‹
[3-5 ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ñ‚ĞµĞ¼]

## ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¸Ğ´ĞµĞ¸
[Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğµ Ğ¸Ğ´ĞµĞ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°]

## Ğ’Ğ°Ğ¶Ğ½Ñ‹Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ
[Ğ¢ĞµÑ€Ğ¼Ğ¸Ğ½Ñ‹ Ğ¸ Ğ¸Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ]
""",

            "key_concepts": """Ğ—ĞĞ”ĞĞ§Ğ: Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:
## ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸
| ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ | ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ | ĞĞ²Ñ‚Ğ¾Ñ€ (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ) |
|----------|-------------|-------------------|

## ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€ĞºĞ¸
[ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸]

## Ğ¡Ğ²ÑĞ·Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸ÑĞ¼Ğ¸
[ĞšĞ°Ğº ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸ ÑĞ²ÑĞ·Ğ°Ğ½Ñ‹ Ğ´Ñ€ÑƒĞ³ Ñ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¼]
""",

            "coaching_tools": """Ğ—ĞĞ”ĞĞ§Ğ: Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ ĞºĞ¾ÑƒÑ‡Ğ¸Ğ½Ğ³Ğ°

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:
## Ğ¢ĞµÑ…Ğ½Ğ¸ĞºĞ¸ Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ¶Ğ½ĞµĞ½Ğ¸Ñ
- **ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ**: ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ

## ĞœĞ¾Ñ‰Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹
[Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸Ğ· Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ°]

## ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
[ĞšĞ°Ğº Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ½Ğ° Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞµ]
""",

            "questions": """Ğ—ĞĞ”ĞĞ§Ğ: Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ğ¾ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ñƒ

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:
## Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ
[5 Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºÑƒ]

## Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸
[5 Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²]

## Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¸
[5 Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸]
""",

            "full_analysis": """Ğ—ĞĞ”ĞĞ§Ğ: ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ°

Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:

## 1. Ğ˜Ğ—Ğ’Ğ›Ğ•Ğ§Ğ•ĞĞĞ«Ğ™ Ğ¢Ğ•ĞšĞ¡Ğ¢
[Ğ’ĞµÑÑŒ Ñ‚ĞµĞºÑÑ‚ ÑĞ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸ĞµĞ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹]

## 2. Ğ’Ğ˜Ğ—Ğ£ĞĞ›Ğ¬ĞĞ«Ğ• Ğ­Ğ›Ğ•ĞœĞ•ĞĞ¢Ğ«
[ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ², ÑÑ…ĞµĞ¼, Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹]

## 3. ĞšĞ›Ğ®Ğ§Ğ•Ğ’Ğ«Ğ• ĞšĞĞĞ¦Ğ•ĞŸĞ¦Ğ˜Ğ˜
| ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ | ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ | ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ |
|-----------|-------------|------------|

## 4. Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞœĞ•ĞĞ¢Ğ« Ğ˜ Ğ¢Ğ•Ğ¥ĞĞ˜ĞšĞ˜
[ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹]

## 5. Ğ’ĞĞ–ĞĞ«Ğ• Ğ¦Ğ˜Ğ¢ĞĞ¢Ğ«
[ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸]

## 6. Ğ¢Ğ•Ğ“Ğ˜
[5-10 ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°]
"""
        }

        return base_prompt + mode_prompts.get(mode, mode_prompts["extract_text"])

    def process_pages(self, images: List[Image.Image], mode: str = "full_analysis",
                      page_start: int = 1) -> List[Dict]:
        """
        ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ‡ĞµÑ€ĞµĞ· Claude Vision.

        Args:
            images: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº PIL Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
            mode: Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
            page_start: ĞĞ¾Ğ¼ĞµÑ€ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹

        Returns:
            List[Dict]: Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        """
        results = []
        max_pages = self.config["max_pages_per_request"]
        system_prompt = self.get_system_prompt(mode)

        # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        for i in range(0, len(images), max_pages):
            batch = images[i:i + max_pages]
            page_nums = list(range(page_start + i, page_start + i + len(batch)))

            print(f"\nğŸ“ ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ {page_nums[0]}-{page_nums[-1]}...")

            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸
            content = []

            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞºÑÑ‚ Ñ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ°Ğ¼Ğ¸ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†
            content.append({
                "type": "text",
                "text": f"ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ {page_nums[0]}-{page_nums[-1]} Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°:"
            })

            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
            for j, img in enumerate(batch):
                img_base64 = self.image_to_base64(img)
                content.append({
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/png",
                        "data": img_base64
                    }
                })
                content.append({
                    "type": "text",
                    "text": f"[Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° {page_nums[j]}]"
                })

            try:
                response = self.client.messages.create(
                    model=self.config["model"],
                    max_tokens=self.config["max_output_tokens"],
                    system=system_prompt,
                    messages=[{"role": "user", "content": content}]
                )

                result = {
                    "pages": page_nums,
                    "page_range": f"{page_nums[0]}-{page_nums[-1]}",
                    "mode": mode,
                    "processed_at": datetime.now().isoformat(),
                    "response": response.content[0].text,
                    "usage": {
                        "input_tokens": response.usage.input_tokens,
                        "output_tokens": response.usage.output_tokens
                    },
                    "status": "success"
                }

                print(f"   âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ ({result['usage']['input_tokens']}â†’{result['usage']['output_tokens']} Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²)")

            except Exception as e:
                result = {
                    "pages": page_nums,
                    "page_range": f"{page_nums[0]}-{page_nums[-1]}",
                    "mode": mode,
                    "processed_at": datetime.now().isoformat(),
                    "error": str(e),
                    "status": "error"
                }
                print(f"   âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")

            results.append(result)

        return results

    def process_pdf(self, pdf_path: str, mode: str = "full_analysis",
                    page_range: Tuple[int, int] = None) -> Dict:
        """
        ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ PDF Ñ‡ĞµÑ€ĞµĞ· Vision.

        Args:
            pdf_path: ĞŸÑƒÑ‚ÑŒ Ğº PDF
            mode: Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
            page_range: Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† (start, end), None = Ğ²ÑĞµ

        Returns:
            Dict: Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        """
        pdf_path = Path(pdf_path)

        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ID ÑĞµÑÑĞ¸Ğ¸
        pdf_hash = hashlib.md5(pdf_path.name.encode()).hexdigest()[:8]
        session_id = f"{pdf_path.stem}_vision_{pdf_hash}"

        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ğŸ‘ï¸ PDF Vision Processor                                   â•‘
â•‘     Claude Vision Ğ´Ğ»Ñ Ğ»ÑĞ±Ñ‹Ñ… PDF                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

        # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ PDF Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
        images = self.pdf_to_images(pdf_path)

        # Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†
        if page_range:
            start, end = page_range
            images = images[start-1:end]
            page_start = start
        else:
            page_start = 1

        total_pages = len(images)

        print(f"\nğŸš€ ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ {total_pages} ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ '{mode}'")
        print("=" * 50)

        # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
        results = self.process_pages(images, mode, page_start)

        # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
        final_result = {
            "session_id": session_id,
            "source_pdf": str(pdf_path),
            "mode": mode,
            "total_pages": total_pages,
            "processed_at": datetime.now().isoformat(),
            "results": results,
            "successful_batches": sum(1 for r in results if r["status"] == "success"),
            "total_tokens": {
                "input": sum(r.get("usage", {}).get("input_tokens", 0) for r in results),
                "output": sum(r.get("usage", {}).get("output_tokens", 0) for r in results)
            }
        }

        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
        output_json = self.output_dir / f"{session_id}_processed.json"
        with open(output_json, "w", encoding="utf-8") as f:
            json.dump(final_result, f, ensure_ascii=False, indent=2)

        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Markdown
        output_md = self.output_dir / f"{session_id}_processed.md"
        self._save_as_markdown(final_result, output_md)

        print("\n" + "=" * 50)
        print(f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!")
        print(f"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:")
        print(f"   - Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†: {total_pages}")
        print(f"   - Ğ£ÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… Ğ±Ğ°Ñ‚Ñ‡ĞµĞ¹: {final_result['successful_batches']}/{len(results)}")
        print(f"   - Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {final_result['total_tokens']['input']:,} Ğ²Ñ…Ğ¾Ğ´ / {final_result['total_tokens']['output']:,} Ğ²Ñ‹Ñ…Ğ¾Ğ´")
        print(f"\nğŸ“ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹:")
        print(f"   - JSON: {output_json}")
        print(f"   - Markdown: {output_md}")

        return final_result

    def _save_as_markdown(self, result: Dict, output_path: Path):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ² Markdown."""

        md_content = f"""# ğŸ‘ï¸ Vision Analysis: {Path(result['source_pdf']).name}

**Ğ”Ğ°Ñ‚Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸:** {result['processed_at']}
**Ğ ĞµĞ¶Ğ¸Ğ¼:** {result['mode']}
**Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†:** {result['total_pages']}
**Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ²:** {result['total_tokens']['input']:,} Ğ²Ñ…Ğ¾Ğ´ / {result['total_tokens']['output']:,} Ğ²Ñ‹Ñ…Ğ¾Ğ´

---

"""

        for r in result["results"]:
            if r["status"] == "success":
                md_content += f"""
## Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ {r['page_range']}

{r['response']}

---
"""

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(md_content)


def main():
    """CLI Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ."""
    parser = argparse.ArgumentParser(
        description="PDF Vision Processor - Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· PDF Ñ‡ĞµÑ€ĞµĞ· Claude Vision"
    )

    subparsers = parser.add_subparsers(dest="command", help="ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹")

    # ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° process
    process_parser = subparsers.add_parser("process", help="ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ PDF Ñ‡ĞµÑ€ĞµĞ· Vision")
    process_parser.add_argument("pdf_path", help="ĞŸÑƒÑ‚ÑŒ Ğº PDF Ñ„Ğ°Ğ¹Ğ»Ñƒ")
    process_parser.add_argument(
        "--mode", "-m",
        choices=["extract_text", "summary", "key_concepts", "coaching_tools", "questions", "full_analysis"],
        default="full_analysis",
        help="Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ (default: full_analysis)"
    )
    process_parser.add_argument(
        "--pages", "-p",
        help="Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: 1-10)"
    )
    process_parser.add_argument(
        "--dpi",
        type=int,
        default=150,
        help="DPI Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸ (default: 150)"
    )

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    try:
        processor = PDFVisionProcessor()

        if args.command == "process":
            # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†
            page_range = None
            if args.pages:
                parts = args.pages.split("-")
                page_range = (int(parts[0]), int(parts[1]))

            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ DPI ĞµÑĞ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½
            if args.dpi:
                processor.config["dpi"] = args.dpi

            processor.process_pdf(
                args.pdf_path,
                mode=args.mode,
                page_range=page_range
            )

    except Exception as e:
        print(f"\nâŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
